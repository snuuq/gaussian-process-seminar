%----------------------------------------------------------------------------------------
%    PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass[aspectratio=169,xcolor=dvipsnames]{beamer}
\usetheme{SimpleDarkBlue}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{kotex} % For Korean language
\usepackage{amsmath,amssymb,amsthm}
\usepackage{bm}

\usepackage{hyperref}
\definecolor{links}{rgb}{0.36,0.54,0.66}
\hypersetup{
   colorlinks = true,
    linkcolor = black,
     urlcolor = blue,
    % citecolor = blue,
    filecolor = blue,
   pdfproducer = {LaTeX},
   pdfcreator = {pdfLaTeX},
   }
\setbeamertemplate{caption}[numbered]

%----------------------------------------------------------------------------------------
%    TITLE PAGE
%----------------------------------------------------------------------------------------

\title{Ch2. Gaussian Processes (Part 1)}
\subtitle{Bayesian Optimization Seminar}

\author{Sungwoo Park}

\institute
{
    Uncertainty Quantification Lab \\
    Seoul National University
}
\date{\today}

% add section contents pages
\AtBeginSection[]
{
    \begin{frame}
    \frametitle{Contents}
    \tableofcontents[currentsection]
    \end{frame}
}

%----------------------------------------------------------------------------------------
%    PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

\begin{document}

\begin{frame}
    % Print the title page as the first slide
    \titlepage
\end{frame}

\begin{frame}{Overview}
    \tableofcontents
\end{frame}


%------------------------------------------------
\section{Review of Chapter 1: Introduction}
%------------------------------------------------

\begin{frame}{The Optimization Problem}
    \begin{block}{Goal}
        Find the global optimum of an objective function $f: \mathcal{X} \to \mathbb{R}$:
        \[
            x^* = \arg\max_{x \in \mathcal{X}} f(x); \quad f^* = \max_{x \in \mathcal{X}} f(x)
        \]
    \end{block}

    \vspace{0.3cm}
    \textbf{Setting}:
    \begin{itemize}
        \item Objective function $f$ is \alert{expensive} to evaluate (time, cost, resources)
        \item We can only access $f$ through \alert{sequential observations}
        \item Observations may be \alert{noisy}: $y = f(x) + \varepsilon$
    \end{itemize}

    \vspace{0.3cm}
    \textbf{Challenge}: How do we decide where to observe next, given limited budget?
\end{frame}

%------------------------------------------------

\begin{frame}{Observation Model}
    Observations are realized by a stochastic mechanism:
    \[
        p(y \mid x, \phi), \quad \text{where } \phi = f(x)
    \]

    \vspace{0.3cm}
    \textbf{Common model --- Additive Gaussian noise}:
    \[
        y = \phi + \varepsilon, \quad \varepsilon \sim \mathcal{N}(0, \sigma_n^2)
    \]
    \[
        \Rightarrow \quad p(y \mid x, \phi, \sigma_n) = \mathcal{N}(y; \phi, \sigma_n^2)
    \]

    \vspace{0.3cm}
    \textbf{Assumption}: Multiple observations are \alert{conditionally independent} given the objective function values:
    \[
        p(\mathbf{y} \mid \mathbf{x}, \bm{\phi}) = \prod_i p(y_i \mid x_i, \phi_i)
    \]
\end{frame}

%------------------------------------------------

\begin{frame}{The Bayesian Approach: Key Idea}
    \begin{block}{Core Principle}
        Treat the unknown objective function $f$ as a \alert{random variable} and use \textbf{Bayesian inference} to reason about it.
    \end{block}

    \vspace{0.3cm}
    \textbf{Bayesian Inference Refresher}:
    \begin{enumerate}
        \item Start with a \textbf{prior} $p(\phi \mid x)$ encoding initial beliefs
        \item Observe data $\mathcal{D} = (x, y)$ via the \textbf{likelihood} $p(y \mid x, \phi)$
        \item Update to the \textbf{posterior} via Bayes' rule:
              \[
                  p(\phi \mid \mathcal{D}) = \frac{p(y \mid x, \phi) \, p(\phi \mid x)}{p(y \mid x)}
              \]
    \end{enumerate}

    \vspace{0.2cm}
    The posterior captures what we now believe about $\phi$ after seeing the data.
\end{frame}

%------------------------------------------------

\begin{frame}{Inference of the Objective Function}
    To reason about the \textit{entire} objective function $f: \mathcal{X} \to \mathbb{R}$, we need a \alert{stochastic process} --- a probability distribution over functions.

    \vspace{0.3cm}
    \begin{block}{Specifying a Stochastic Process}
        We specify the distribution of function values $\bm{\phi} = f(\mathbf{x})$ for any finite set of locations $\mathbf{x} \subset \mathcal{X}$:
        \[
            p(\bm{\phi} \mid \mathbf{x})
        \]
    \end{block}

    \vspace{0.3cm}
    \textbf{Gaussian Processes}: The family where all such finite-dimensional distributions are \alert{multivariate Gaussian} --- mathematically convenient and widely used in Bayesian optimization.
\end{frame}

%------------------------------------------------

\begin{frame}{Posterior Predictive Distribution}
    After observing data $\mathcal{D}$, we can predict the outcome of a new observation at $x$:

    \begin{block}{Posterior Predictive Distribution}
        \[
            p(y' \mid x, \mathcal{D}) = \int p(y' \mid x, \phi) \, p(\phi \mid x, \mathcal{D}) \, d\phi
        \]
    \end{block}

    \vspace{0.3cm}
    \textbf{Interpretation}:
    \begin{itemize}
        \item Integrates over all possible values of $\phi = f(x)$
        \item Weights by their plausibility under the posterior
        \item Naturally accounts for \alert{uncertainty} in the objective function
    \end{itemize}

    \vspace{0.2cm}
    This distribution is \textit{instrumental} for making informed decisions about where to observe next.
\end{frame}

%------------------------------------------------
\section{Definition and Basic Properties}
%------------------------------------------------

\begin{frame}{What is a Gaussian Process?}
    A \alert{Gaussian process (GP)} extends the multivariate normal distribution to model functions on infinite domains.

    \begin{block}{Key Idea}
        We model an objective function $f: \mathcal{X} \to \mathbb{R}$ as an infinite collection of random variables, one for each point in the domain. The \textbf{Kolmogorov extension theorem} allows us to specify this distribution through finite-dimensional marginals.
    \end{block}

    \vspace{0.3cm}
    GPs inherit convenient mathematical properties of the multivariate normal distribution while remaining computationally tractable.
\end{frame}

%------------------------------------------------

\begin{frame}{Recall: Kolmogorov's Extension Theorem}
    \begin{exampleblock}{Question}
        What is the \emph{consistency} property in Kolmogorov's Extension Theorem?
    \end{exampleblock}

    \begin{block}{Kolmogorov's Extension Theorem \cite{Durrett2019-gs}}
        Suppose we are given probability measures \( \mu_n \) on \( (\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n)) \) that are \emph{consistent}, that is,
        \[
            \mu_{n+1}((a_1, b_1] \times \cdots \times (a_{n+1}, b_{n+1}] \times \mathbf{R}) = \mu_n((a_1, b_1] \times \cdots \times (a_n, b_n])
        \]
        Then there is a unique probability measure \( P \) on \( (\mathbb{R}^\mathbf{N}, \mathcal{B}(\mathbb{R}^\mathbf{N})) \) with
        \[
            P(\omega : \omega_i \in (a_i, b_i], 1 \geq i \geq n) = \mu_n((a_1, b_1] \times \cdots \times (a_n, b_n])
        \]
        where \( \mathbf{N} = \left\{ 1, 2, \cdots \right\} \) and \( \mathcal{B}(\mathbb{R}^\mathbf{N}) = \left\{ (\omega_1, \omega_2, \cdots) : \omega_i \in \mathcal{B}(\mathbb{R}) \right\} \)
    \end{block}

    \vspace{0.3cm}

    In \cite{Durrett2019-gs}, theorem is not complete to use in our senario because \(P\) defines on countable index set \(\mathbf{N}\).
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: Countable vs.\ Uncountable Domains}

    \begin{exampleblock}{Question}
        What are the characteristics of modeling on countable vs uncountable domains?
    \end{exampleblock}

    \begin{block}{Definition: Sample path \cite{Le-Gall2016-ik}}
        Let \((X_t)_{t \in \mathcal{X}} \) be a random process with values in \(E\). The \emph{sample paths of \(X\)} are the mappings \( \mathcal{X} \ni t \mapsto X_t(\omega) \) obtained when fixing \( \omega \in \Omega \). The sample paths of \(X\) is thus form a collection of mappings from \(\mathcal{X}\) into \(E\) indexed by \(\omega \in \Omega\).
    \end{block}

    \vspace{0.3cm}
    \textbf{Countable infinite domain} (e.g., $\mathcal{X} = \mathbb{Z}$):
    \begin{itemize}
        \item GP reduces to specifying consistent MVN distributions on all finite subsets
        \item Sample paths are sequences $\{f(x_i)\}_{i=1}^\infty$
        \item No notion of ``continuity'' in the classical sense
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: Countable vs.\ Uncountable Domains}

    \begin{exampleblock}{Question}
        What are the characteristics of modeling on countable vs uncountable domains?
    \end{exampleblock}

    \begin{block}{Definition: Sample path \cite{Le-Gall2016-ik}}
        Let \((X_t)_{t \in \mathcal{X}} \) be a random process with values in \(E\). The \emph{sample paths of \(X\)} are the mappings \( \mathcal{X} \ni t \mapsto X_t(\omega) \) obtained when fixing \( \omega \in \Omega \). The sample paths of \(X\) is thus form a collection of mappings from \(\mathcal{X}\) into \(E\) indexed by \(\omega \in \Omega\).
    \end{block}

    \vspace{0.2cm}
    \textbf{Uncountable infinite domain} (e.g., $\mathcal{X} = \mathbb{R}^d$):
    \begin{itemize}
        \item Sample paths are actual functions
        \item Continuity, differentiability become meaningful properties
        \item Requires careful treatment (measurability issues, sample path properties)
    \end{itemize}
\end{frame}

%------------------------------------------------


\begin{frame}{Kolmogorov Extension Theorem: The Foundation}
    \begin{exampleblock}{Question}
        What is the \emph{consistency} property in Kolmogorov's Extension Theorem?
    \end{exampleblock}

    \begin{block}{Kolmogorov's Extension Theorem : Stochastic process ver. \cite{Oksendal2003-nf}}
        For all $t_1, \ldots, t_k \in T$, $k \in \mathbb{N}$ let $\nu_{t_1,\ldots,t_k}$ be probability measures on $\mathbb{R}^{nk}$ s.t.

        \begin{equation}
            \nu_{t_{\sigma(1)},\ldots,t_{\sigma(k)}}(F_1 \times \cdots \times F_k) = \nu_{t_1,\ldots,t_k}(F_{\sigma^{-1}(1)} \times \cdots \times F_{\sigma^{-1}(k)})
            \tag{K1}
        \end{equation}

        for all permutations $\sigma$ on $\{1, 2, \ldots, k\}$ and

        \begin{equation}
            \nu_{t_1,\ldots,t_k}(F_1 \times \cdots \times F_k) = \nu_{t_1,\ldots,t_k,t_{k+1},\ldots,t_{k+m}}(F_1 \times \cdots \times F_k \times \mathbb{R}^n \times \cdots \times \mathbb{R}^n)
            \tag{K2}
        \end{equation}

        for all $m \in \mathbb{N}$.
    \end{block}
\end{frame}

%------------------------------------------------


\begin{frame}{Kolmogorov Extension Theorem: The Foundation}
    \begin{block}{Kolmogorov's Extension Theorem : Stochastic process ver. (cont.) \cite{Oksendal2003-nf}}
        Then there exists a probability space $(\Omega, \mathcal{F}, P)$ and a stochastic process $\{X_t\}$ on $\Omega$, $X_t: \Omega \to \mathbb{R}^n$, s.t.

        \[
            \nu_{t_1,\ldots,t_k}(F_1 \times \cdots \times F_k) = P[X_{t_1} \in F_1, \cdots, X_{t_k} \in F_k],
        \]

        for all $t_i \in T$, $k \in \mathbb{N}$ and all Borel sets $F_i$.
    \end{block}

    \vspace{0.3cm}
    \textbf{Consistency Conditions:}
    \begin{enumerate}
        \item \textbf{Permutation invariance} (K1): The joint distribution is unchanged by reordering indices
        \item \textbf{Marginalization consistency} (K2): If $\mathbf{x} \subset \mathbf{x}'$, then marginalizing $p(\bm{\phi}' \mid \mathbf{x}')$ over $\bm{\phi}' \setminus \bm{\phi}$ yields $p(\bm{\phi} \mid \mathbf{x})$
    \end{enumerate}

    \vspace{0.2cm}
    For GPs, these are automatically satisfied because the MVN satisfies them (the marginal of a MVN is MVN with the corresponding submatrix of the covariance).
\end{frame}

%------------------------------------------------

\begin{frame}{GP Specification: Mean and Covariance Functions}
    A GP on $f$ is specified by:
    \[
        p(f) = \mathcal{GP}(f; \mu, K)
    \]

    \begin{itemize}
        \item \textbf{Mean function} $\mu: \mathcal{X} \to \mathbb{R}$: determines the expected function value
              \[
                  \mu(x) = \mathbb{E}[\phi \mid x], \quad \text{where } \phi = f(x)
              \]

        \item \textbf{Covariance function (kernel)} $K: \mathcal{X} \times \mathcal{X} \to \mathbb{R}$: encodes the correlation structure
              \[
                  K(x, x') = \text{cov}[\phi, \phi' \mid x, x'], \quad \text{where } \phi' = f(x')
              \]
    \end{itemize}

    The covariance function must be \alert{symmetric} and \alert{positive semidefinite}.
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: Extension from Countable Dense Subsets}
    \begin{exampleblock}{Question}
        If $f$ is a.s.\ continuous and $D \subset \mathcal{X}$ is countable dense, can $p(f \mid D)$ determine $p(f)$?
    \end{exampleblock}

    \begin{proof}
        Let \( f \) and \( g \) be two continuous functions on \( \mathcal{X} \). Suppose they agree on a dense subset \( D \subseteq \mathcal{X} \). For any \( x \in \mathcal{X} \), there exists a sequence \( \{q_n\} \subset D \) such that \( q_n \to x \). By continuity,
        \[
            f(x) = f(\lim_{n \to \infty} q_n) = \lim_{n \to \infty} f(q_n) = \lim_{n \to \infty} g(q_n) = g(\lim_{n \to \infty} q_n) = g(x)
        \]
        Thus, \( f(x) = g(x) \) for all \( x \in \mathcal{X} \).
        Since sample paths are a.s.\ continuous, the process is uniquely determined by its values on \( D \).
    \end{proof}
\end{frame}

%------------------------------------------------

\begin{frame}{Finite-Dimensional Marginals}
    For any finite set of points $\mathbf{x} \subset \mathcal{X}$, the corresponding function values $\bm{\phi} = f(\mathbf{x})$ follow a multivariate normal distribution:
    \[
        p(\bm{\phi} \mid \mathbf{x}) = \mathcal{N}(\bm{\phi}; \bm{\mu}, \bm{\Sigma})
    \]
    where
    \[
        \bm{\mu} = \mathbb{E}[\bm{\phi} \mid \mathbf{x}] = \mu(\mathbf{x}); \quad \bm{\Sigma} = \text{cov}[\bm{\phi} \mid \mathbf{x}] = K(\mathbf{x}, \mathbf{x})
    \]

    \begin{block}{Gram Matrix}
        $K(\mathbf{x}, \mathbf{x})$ is the matrix formed by evaluating $K$ for each pair of points:
        \[
            \Sigma_{ij} = K(x_i, x_j)
        \]
    \end{block}
\end{frame}

%------------------------------------------------

\begin{frame}{Example: Squared Exponential Covariance}
    \begin{center}
        \begin{figure}
            \includegraphics[width = 14cm]{figure/fig-1-GP.png}
            \caption{Example of Gaussian Process \cite{Garnett2023-gc}}
        \end{figure}
    \end{center}

    Consider $\mathcal{X} = [0, 30]$ with:
    \begin{itemize}
        \item Mean function: $\mu \equiv 0$ (constant central tendency)
        \item Covariance function (squared exponential):
              \[
                  K(x, x') = \exp\left(-\frac{1}{2}|x - x'|^2\right)
              \]
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Example: Squared Exponential Covariance}
    \addtocounter{figure}{-1}
    \begin{center}
        \begin{figure}
            \includegraphics[width = 14cm]{figure/fig-1-GP.png}
            \caption{Example of Gaussian Process \cite{Garnett2023-gc}}
        \end{figure}
    \end{center}

    \textbf{Properties:}
    \begin{itemize}
        \item $\text{var}[\phi \mid x] = K(x,x) = 1$ at every point
        \item Correlation decreases with distance: nearby values are highly correlated, distant values are nearly independent
        \item This encodes a statistical notion of \alert{continuity}
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Sampling from a Gaussian Process (Appendix A.2)}
    To sample from a GP with mean $\mu$ and covariance $K$:

    \begin{enumerate}
        \item Choose a finite grid of points $\mathbf{x} = (x_1, \ldots, x_n)$
        \item Compute $\bm{\mu} = \mu(\mathbf{x})$ and $\bm{\Sigma} = K(\mathbf{x}, \mathbf{x})$
        \item Factor: $\bm{\Sigma} = \mathbf{L}\mathbf{L}^\top$ (Cholesky decomposition)
        \item Sample $\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$
        \item Compute $\bm{\phi} = \bm{\mu} + \mathbf{L}\mathbf{z}$
    \end{enumerate}

    \vspace{0.3cm}
    The resulting sample $\bm{\phi}$ represents function values at the chosen grid points, respecting the correlation structure encoded by $K$.
\end{frame}

%------------------------------------------------
\section{Inference with Exact and Noisy Observations}
%------------------------------------------------

\begin{frame}{General Framework: Jointly Gaussian Observations}
    We can condition a GP $p(f) = \mathcal{GP}(f; \mu, K)$ on any vector $\mathbf{y}$ sharing a joint Gaussian distribution with $f$:
    \[
        p(f, \mathbf{y}) = \mathcal{GP}\left(\begin{bmatrix} f \\ \mathbf{y} \end{bmatrix}; \begin{bmatrix} \mu \\ \mathbf{m} \end{bmatrix}, \begin{bmatrix} K & \bm{\kappa}^\top \\ \bm{\kappa} & \mathbf{C} \end{bmatrix}\right)
    \]

    where:
    \begin{itemize}
        \item $p(\mathbf{y}) = \mathcal{N}(\mathbf{y}; \mathbf{m}, \mathbf{C})$ : marginal distribution of observations
        \item $\bm{\kappa}(x) = \text{cov}[\mathbf{y}, \phi \mid x]$ : cross-covariance function
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: What Observations $\mathbf{y}$ Are Jointly Gaussian with $f$?}
    \begin{exampleblock}{Question}
        Besides function values, what else can $\mathbf{y}$ be?
    \end{exampleblock}

    \vspace{0.3cm}
    Any of the following are jointly Gaussian with a GP:
    \begin{itemize}
        \item Function values: $\mathbf{y} = f(\mathbf{x})$ (the basic case)
        \item Affine transformations: $\mathbf{y} = \mathbf{A} f(\mathbf{x}) + \mathbf{b}$
        \item Limits of affine transformations:
              \begin{itemize}
                  \item Partial derivatives: $\frac{\partial f}{\partial x_i}(x)$
                  \item Integrals/expectations: $\int f(x) p(x) dx$
              \end{itemize}
        \item Any of the above + independent Gaussian noise
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: What Observations $\mathbf{y}$ Are Jointly Gaussian with $f$?}
    \begin{exampleblock}{Question}
        Besides function values, what else can $\mathbf{y}$ be?
    \end{exampleblock}

    \textbf{Other examples}: Based on linear (affine) operator, these are joint Gaussian distribution.

    \begin{itemize}
        \item Line/Path Integral Observations \cite{Sarkka2011-vy}
              \[\mathbf{y} = \int_\gamma f(x) \, ds + \bm{\varepsilon}, \quad \bm{\kappa}(x') = \int_\gamma K(x, x') \, ds\]
              \small Used at Tomographic reconstruction (CT/MRI), Measure expected path of moving sensor
        \item Convolved/Smoothed Observations by smoothing kernel $G$ \cite{Alvarez2011-vl}
              \[\mathbf{y} = (f * G)(x_0) = \int f(x') G(x_0 - x') \, dx', \quad \bm{\kappa}(x) = \int G(x_0 - x') K(x', x) \, dx'\]
              \small Used at Sensor spatial averaging, image blur (PSF), multi-output GP via convolution
    \end{itemize}

\end{frame}

%------------------------------------------------

\begin{frame}{Posterior Gaussian Process}
    Conditioning on observations $\mathcal{D} = \mathbf{y}$ yields a GP posterior:
    \[
        p(f \mid \mathcal{D}) = \mathcal{GP}(f; \mu_{\mathcal{D}}, K_{\mathcal{D}})
    \]

    \begin{alertblock}{Posterior Mean and Covariance}
        \vspace{-0.3cm}
        \begin{align*}
            \mu_{\mathcal{D}}(x)   & = \mu(x) + \bm{\kappa}(x)^\top \mathbf{C}^{-1}(\mathbf{y} - \mathbf{m}) \\
            K_{\mathcal{D}}(x, x') & = K(x, x') - \bm{\kappa}(x)^\top \mathbf{C}^{-1} \bm{\kappa}(x')
        \end{align*}
    \end{alertblock}

    \vspace{0.2cm}
    \textbf{Inference procedure:}
    \begin{enumerate}
        \item Compute marginal distribution of $\mathbf{y}$
        \item Derive cross-covariance function $\bm{\kappa}$
        \item Apply the posterior formulas
    \end{enumerate}
\end{frame}

%------------------------------------------------

\begin{frame}{Handling Additive Gaussian Noise}
    Suppose we observe $\mathbf{z} = \mathbf{y} + \bm{\varepsilon}$ where $\bm{\varepsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{N})$ is independent noise.

    \vspace{0.3cm}
    Then:
    \[
        p(\mathbf{z} \mid \mathbf{N}) = \mathcal{N}(\mathbf{z}; \mathbf{m}, \mathbf{C} + \mathbf{N}); \quad \text{cov}[\mathbf{z}, \phi \mid x] = \bm{\kappa}(x)
    \]

    \begin{block}{Key Result}
        Simply replace $\mathbf{C}$ with $\mathbf{C} + \mathbf{N}$ in the posterior formulas!
    \end{block}

    \vspace{0.2cm}
    As $\mathbf{N} \to \mathbf{0}$, the posterior converges to that from direct observation of $\mathbf{y}$.
\end{frame}

%------------------------------------------------

\begin{frame}{Inference with Exact Function Evaluations}
    Suppose we observe $f$ at locations $\mathbf{x}$, revealing $\bm{\phi} = f(\mathbf{x})$.

    \vspace{0.3cm}
    The posterior is $p(f \mid \mathcal{D}) = \mathcal{GP}(f; \mu_{\mathcal{D}}, K_{\mathcal{D}})$ with:

    \begin{align*}
        \mu_{\mathcal{D}}(x)   & = \mu(x) + K(x, \mathbf{x}) \bm{\Sigma}^{-1}(\bm{\phi} - \bm{\mu}) \\
        K_{\mathcal{D}}(x, x') & = K(x, x') - K(x, \mathbf{x}) \bm{\Sigma}^{-1} K(\mathbf{x}, x')
    \end{align*}

    where $\bm{\Sigma} = K(\mathbf{x}, \mathbf{x})$ and $\bm{\mu} = \mu(\mathbf{x})$.

    \vspace{0.3cm}
    \textbf{Key properties:}
    \begin{itemize}
        \item Posterior mean \alert{interpolates} through observed points
        \item Posterior variance \alert{vanishes} at observed locations
        \item Uncertainty remains unchanged far from observations
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Inference with Noisy Function Evaluations}
    Suppose observations are corrupted: $\mathbf{y} = \bm{\phi} + \bm{\varepsilon}$ with $\bm{\varepsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{N})$.

    \vspace{0.2cm}
    \textbf{Common noise models:}
    \begin{itemize}
        \item \textbf{Homoskedastic}: $\mathbf{N} = \sigma_n^2 \mathbf{I}$ (constant noise)
        \item \textbf{Heteroskedastic}: $\mathbf{N} = \text{diag}(\sigma_n^2(\mathbf{x}))$ (location-dependent)
    \end{itemize}

    \vspace{0.3cm}
    The posterior formulas become:
    \begin{align*}
        \mu_{\mathcal{D}}(x)   & = \mu(x) + K(x, \mathbf{x})(\bm{\Sigma} + \mathbf{N})^{-1}(\mathbf{y} - \bm{\mu}) \\
        K_{\mathcal{D}}(x, x') & = K(x, x') - K(x, \mathbf{x})(\bm{\Sigma} + \mathbf{N})^{-1}K(\mathbf{x}, x')
    \end{align*}

    \vspace{0.2cm}
    The posterior mean no longer interpolates exactly; extreme values may be ``explained away'' as noise.
\end{frame}

%------------------------------------------------

\begin{frame}{Interpretation of Posterior Moments}
    Consider a single observation $y$ with distribution $\mathcal{N}(y; m, s^2)$ and define:
    \begin{itemize}
        \item $z$-score: $z = \frac{y - m}{s}$
        \item Correlation: $\rho = \text{corr}[y, \phi \mid x] = \frac{\kappa(x)}{\sigma s}$
    \end{itemize}

    \vspace{0.3cm}
    \begin{alertblock}{Posterior Moments (Scalar Case)}
        \vspace{-0.5cm}
        \begin{align*}
            \text{Posterior mean of } \phi & : \mu + \sigma \rho z      \\
            \text{Posterior std of } \phi  & : \sigma \sqrt{1 - \rho^2}
        \end{align*}
    \end{alertblock}

    \vspace{0.2cm}
    \textbf{Intuition:}
    \begin{itemize}
        \item Mean shifts proportionally to $z$-score and correlation strength
        \item Variance reduction depends only on correlation $|\rho|$
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: Differential Entropy as Global Uncertainty}
    \begin{exampleblock}{Question}
        Why is differential entropy a measure of global uncertainty?
    \end{exampleblock}

    \vspace{0.3cm}
    \begin{block}{Definition: Differential Entropy}
        For a random variable $\omega$ with density $p(\omega)$, \emph{differential entropy} is defined as:
        \[
            H[\omega] = -\int p(\omega) \log p(\omega) \, d\omega
        \]
    \end{block}

    \textbf{Interpretation}:
    \begin{itemize}
        \item Measures the ``spread'' or ``uncertainty'' in the distribution
        \item Higher entropy $\Rightarrow$ more uncertain (flatter distribution)
        \item For Gaussian: $H[\mathcal{N}(\mu, \sigma^2)] = \frac{1}{2}\log(2\pi e \sigma^2)$
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: Differential Entropy as Global Uncertainty}
    \begin{exampleblock}{Question}
        Why is differential entropy a measure of global uncertainty?
    \end{exampleblock}

    \vspace{0.3cm}
    \begin{block}{Definition: Differential Entropy}
        For a random variable $\omega$ with density $p(\omega)$, \emph{differential entropy} is defined as:
        \[
            H[\omega] = -\int p(\omega) \log p(\omega) \, d\omega
        \]
    \end{block}

    \vspace{0.2cm}
    \textbf{For GPs}: The joint differential entropy of function values at $\mathbf{x}$ is:
    \[
        H[\bm{\phi} \mid \mathbf{x}] = \frac{1}{2}\log|2\pi e \, K(\mathbf{x}, \mathbf{x})|
    \]
    Observations \textit{reduce} this entropy: $|K_\mathcal{D}(\mathbf{x}, \mathbf{x})| \leq |K(\mathbf{x}, \mathbf{x})|$.
\end{frame}

%------------------------------------------------

\begin{frame}{Posterior Predictive Distribution}
    For the latent function value $\phi = f(x)$:
    \[
        p(\phi \mid x, \mathcal{D}) = \mathcal{N}(\phi; \mu_{\mathcal{D}}(x), K_{\mathcal{D}}(x, x))
    \]

    \vspace{0.3cm}
    For a \alert{noisy observation} $y$ at location $x$ (with noise variance $\sigma_n^2$):
    \[
        p(y \mid x, \mathcal{D}, \sigma_n) = \mathcal{N}(y; \mu_{\mathcal{D}}(x), K_{\mathcal{D}}(x, x) + \sigma_n^2)
    \]

    \vspace{0.3cm}
    The predictive credible intervals for noisy measurements are inflated compared to the latent function, reflecting observation uncertainty.
\end{frame}

%------------------------------------------------
\section{Joint Gaussian Processes}
%------------------------------------------------

\begin{frame}{Topics Covered in Remaining Sections}
    The remainder of Chapter 2 covers more specialized topics:

    \vspace{0.3cm}
    \begin{itemize}
        \item \textbf{\S 2.4 Joint Gaussian Processes}: Modeling multiple correlated functions
        \item \textbf{\S 2.5 Continuity}: Conditions for continuous sample paths
        \item \textbf{\S 2.6 Differentiability}: Conditions for differentiable sample paths; derivative observations
        \item \textbf{\S 2.7 Existence/Uniqueness of Global Maxima}: Theoretical guarantees
        \item \textbf{\S 2.8 Non-Gaussian Observations}: Approximate inference methods
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Motivation: Modeling Multiple Functions}
    In some settings, we need to jointly reason about \alert{multiple related functions}:
    \begin{itemize}
        \item An objective function and its gradient
        \item An expensive objective and cheaper surrogates (multifidelity)
        \item Multiple objectives (multiobjective optimization)
    \end{itemize}

    \vspace{0.3cm}
    \begin{block}{Key Idea}
        ``Paste together'' multiple functions into a single function on a larger domain, then construct a standard GP on this combined function.
    \end{block}
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: Why Disjoint Union for Joint GP Domains?}
    \begin{block}{Question}
        Is disjoint union the standard way to define joint GP domains?
    \end{block}

    \vspace{0.3cm}
    Yes, mathematically this is the cleanest approach:
    \[
        \bigsqcup f: \mathcal{X} = \bigsqcup_i \mathcal{X}_i \to \mathbb{R}, \quad \text{where } (\bigsqcup f)|_{\mathcal{X}_i} \equiv f_i
    \]

    \textbf{Why disjoint union?}
    \begin{itemize}
        \item Ensures each point $(x, i)$ uniquely identifies \textit{which} function
        \item Even if $\mathcal{X}_1 = \mathcal{X}_2 = [0, 1]$, we distinguish $f_1(0.5)$ from $f_2(0.5)$
        \item The kernel can then define both within-function and cross-function covariance
    \end{itemize}

    \vspace{0.2cm}
    \textbf{Alternative}: If functions share a domain and we want $f(x) \approx g(x)$, we can use a \textit{separable} kernel structure without explicit disjoint union.
\end{frame}

%------------------------------------------------

\begin{frame}{Definition of Joint Gaussian Process}
    Consider functions $\{f_i: \mathcal{X}_i \to \mathbb{R}\}$. Define the \textbf{disjoint union}:
    \[
        \bigsqcup f: \mathcal{X} \to \mathbb{R}, \quad \mathcal{X} = \bigsqcup \mathcal{X}_i
    \]
    such that $\bigsqcup f|_{\mathcal{X}_i} \equiv f_i$.

    \vspace{0.3cm}
    A \alert{joint Gaussian process} is a GP on $\bigsqcup f$:
    \[
        p(\bigsqcup f) = \mathcal{GP}(\bigsqcup f; \mu, K)
    \]

    \vspace{0.3cm}
    The mean and covariance functions on $\mathcal{X}$ encode both:
    \begin{itemize}
        \item Marginal behavior of each function
        \item Cross-correlations between functions
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Decomposed Notation}
    For two functions $f: \mathcal{F} \to \mathbb{R}$ and $g: \mathcal{G} \to \mathbb{R}$:

    \[
        p(f, g) = \mathcal{GP}\left(\begin{bmatrix} f \\ g \end{bmatrix}; \begin{bmatrix} \mu_f \\ \mu_g \end{bmatrix}, \begin{bmatrix} K_f & K_{fg} \\ K_{gf} & K_g \end{bmatrix}\right)
    \]

    \vspace{0.3cm}
    \textbf{Components:}
    \begin{itemize}
        \item $\mu_f, K_f$ and $\mu_g, K_g$: marginal GP parameters
        \item $K_{fg}(x, x') = \text{cov}[\phi, \gamma \mid x, x']$: cross-covariance
        \item $K_{gf} = K_{fg}^\top$
    \end{itemize}

    \vspace{0.3cm}
    \textbf{Marginal property}: Each function has a marginal GP distribution:
    \[
        p(f) = \mathcal{GP}(f; \mu_f, K_f); \quad p(g) = \mathcal{GP}(g; \mu_g, K_g)
    \]
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: Designing Cross-Covariance Functions}
    \begin{exampleblock}{Question}
        How do we choose the cross-covariance function $K_{fg}$?
    \end{exampleblock}

    \vspace{0.3cm}
    \textbf{Common approaches}:
    \begin{enumerate}
        \item \textbf{Scaled base kernel}: $K_{fg}(x, x') = \rho \cdot K(x, x')$ where $|\rho| < 1$
              \begin{itemize}
                  \item Simple, interpretable: $\rho$ is the correlation at any point
              \end{itemize}
        \item \textbf{Linear Model of Coregionalization (LMC)}:
              \[
                  K_{fg}(x, x') = \sum_{q=1}^Q a_q^{(f)} a_q^{(g)} K_q(x, x')
              \]
        \item \textbf{Convolution processes}: Define via convolution with a smoothing kernel
    \end{enumerate}

    \vspace{0.2cm}
    \textbf{Constraint}: The full covariance matrix must remain positive semidefinite!
\end{frame}

%------------------------------------------------

\begin{frame}{Example: Correlated Functions}
    \begin{center}
        \begin{figure}
            \includegraphics[width = 14cm]{figure/fig-2-joint-GP.png}
            \caption{Example of Joint Gaussian Process \cite{Garnett2023-gc}}
        \end{figure}
    \end{center}

    Consider $f, g: [0, 30] \to \mathbb{R}$ with:
    \begin{itemize}
        \item Same marginal: $\mu \equiv 0$, squared exponential covariance $K$
        \item Cross-covariance: $K_{fg}(x, x') = 0.9 \cdot K(x, x')$
    \end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}{Example: Correlated Functions}
    \addtocounter{figure}{-1}
    \begin{center}
        \begin{figure}
            \includegraphics[width = 14cm]{figure/fig-2-joint-GP.png}
            \caption{Example of Joint Gaussian Process \cite{Garnett2023-gc}}
        \end{figure}
    \end{center}

    For any point $x$, the correlation between $\phi = f(x)$ and $\gamma = g(x)$ is:
    \[
        \text{corr}[\phi, \gamma \mid x] = 0.9
    \]

    \vspace{0.3cm}
    \textbf{Consequence}: Samples from the joint distribution show strong coupling, the functions ``move together.''
\end{frame}

%------------------------------------------------

\begin{frame}{Q\&A: Domain Size and Function Influence in Joint GPs}
    \begin{exampleblock}{Question}
        Can domain size differences affect function influence in joint GPs?
    \end{exampleblock}

    \vspace{0.3cm}
    Yes, this is a real concern in practice!

    \begin{itemize}
        \item Function with more observations may dominate inference
        \item Different scales of domains may require different length scales
        \item Numerical conditioning can suffer from imbalanced data
    \end{itemize}

    \vspace{0.2cm}
    \textbf{Mitigation strategies}:
    \begin{enumerate}
        \item \textbf{Output scaling}: Normalize each function to similar variance
        \item \textbf{Separate length scales}: Use ARD-style kernels for each function
        \item \textbf{Weighted likelihoods}: Down-weight abundant data sources
        \item \textbf{Hierarchical priors}: Place priors on correlation parameters
    \end{enumerate}
\end{frame}

%------------------------------------------------

\begin{frame}{Inference for Joint GPs}
    The joint GP construction allows us to condition on observations of \alert{any} of the functions using the standard inference procedure.

    \vspace{0.3cm}
    \begin{examples}
        Given observations of $f$ on the left side of the domain and observations of $g$ on the right side:
        \begin{itemize}
            \item Observations of $f$ inform our belief about $g$ (and vice versa)
            \item Information propagates through the cross-covariance structure
            \item Strong correlation $\Rightarrow$ strong information transfer
        \end{itemize}
    \end{examples}

    \vspace{0.3cm}
    This is particularly useful for \alert{multifidelity optimization}: cheap surrogate evaluations inform our belief about the expensive objective.
\end{frame}

%------------------------------------------------

\begin{frame}{Extension to Vector-Valued Functions}
    A GP on a vector-valued function $\mathbf{f}: \mathcal{X} \to \mathbb{R}^d$ is defined by a joint GP on its coordinate functions $\{f_i\}: \mathcal{X} \to \mathbb{R}$.

    \vspace{0.3cm}
    Notation: $\mathcal{GP}(\mathbf{f}; \mu, K)$ where:
    \begin{itemize}
        \item $\mu: \mathcal{X} \to \mathbb{R}^d$ (vector-valued mean)
        \item $K: \mathcal{X} \times \mathcal{X} \to \mathbb{R}^{d \times d}$ (matrix-valued covariance)
    \end{itemize}

    \vspace{0.3cm}
    \textbf{Applications:}
    \begin{itemize}
        \item Joint distribution of $f$ and $\nabla f$ (gradient)
        \item Multiobjective optimization with correlated objectives
        \item Modeling spatial vector fields
    \end{itemize}
\end{frame}

%------------------------------------------------
\section{Summary}
%------------------------------------------------

\begin{frame}{Summary of Key Ideas}
    \begin{enumerate}
        \item \textbf{GP Definition}: Specified by mean $\mu$ and covariance $K$ functions; finite marginals are multivariate Gaussian

              \vspace{0.2cm}
        \item \textbf{Exact Inference}: Conditioning on jointly Gaussian observations yields a GP posterior with closed-form mean and covariance

              \vspace{0.2cm}
        \item \textbf{Noisy Inference}: Replace $\mathbf{C}$ with $\mathbf{C} + \mathbf{N}$ to handle additive Gaussian noise

              \vspace{0.2cm}
        \item \textbf{Posterior Interpretation}: Mean update $\propto$ (correlation $\times$ $z$-score); variance reduction depends on correlation strength

              \vspace{0.2cm}
        \item \textbf{Joint GPs}: Model multiple correlated functions; enable information sharing across related tasks
    \end{enumerate}
\end{frame}

%------------------------------------------------

\begin{frame}{References}
    \footnotesize
    \bibliography{ref.bib}
    \bibliographystyle{apalike}
\end{frame}

%------------------------------------------------

\begin{frame}
    \Huge{\centerline{\textbf{Thank You}}}
\end{frame}

%----------------------------------------------------------------------------------------

\end{document}